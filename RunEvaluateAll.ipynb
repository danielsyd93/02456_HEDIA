{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example script that optimises hyperparameters and trains model on individual and all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "import datetime\n",
    "import getpass\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from config import code_path, data_path, figure_path, model_path, result_path\n",
    "from optimizeHypers import searchBestHypers\n",
    "from src.evaluation import evaluateModel\n",
    "from src.load_data import dataLoader\n",
    "from src.models.hediaNetExample import DilatedNet\n",
    "from src.parameter_sets.evaluateAllPars import (GRACE_PERIOD, GRACE_PERIOD_FINAL, MAX_NUM_EPOCHS,\n",
    "                                                MAX_NUM_EPOCHS_FINAL, N_EPOCHS_STOP,\n",
    "                                                N_EPOCHS_STOP_FINAL, NUM_SAMPLES, dates, features,\n",
    "                                                test_data_sequence, train_data_sequence,\n",
    "                                                val_data_sequence)\n",
    "from src.tools import train_cgm\n",
    "\n",
    "scores = pd.DataFrame(columns=['Model ID','RMSE', 'MARD', 'MAE',\n",
    "                               'A', 'B', 'C', 'D', 'E', 'precision', 'recall', 'F1', 'lag'])\n",
    "scores.index.name = '[training], test'\n",
    "\n",
    "for i, (train_data, val_data, test_data) in enumerate(zip(train_data_sequence, val_data_sequence, test_data_sequence)):\n",
    "\n",
    "    start_date_train = list(dates['start_date_train'][train_data])\n",
    "    end_date_train = list(dates['end_date_train'][train_data])\n",
    "    start_date_val = dates['start_date_val'][val_data]\n",
    "    end_date_val = dates['end_date_val'][val_data]\n",
    "    start_date_test = dates['start_date_test'][test_data]\n",
    "    end_date_test = dates['end_date_test'][test_data]\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    print('Case #{:d}'.format(i))\n",
    "    print(\"TRAIN DATA:\", train_data)\n",
    "    print(\"VALIDATION DATA:\", val_data)\n",
    "    print(\"TEST DATA:\", test_data)\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Define data object\n",
    "    data_pars = {}\n",
    "    data_pars['path'] = data_path\n",
    "    data_pars['train_data'] = train_data\n",
    "    data_pars['test_data'] = test_data\n",
    "    data_pars['validation_data'] = test_data\n",
    "\n",
    "    data_pars['start_date_train'] = start_date_train\n",
    "    data_pars['start_date_test'] = start_date_test\n",
    "    data_pars['start_date_validation'] = start_date_test\n",
    "\n",
    "    data_pars['end_date_train'] = end_date_train\n",
    "    data_pars['end_date_test'] = end_date_test\n",
    "    data_pars['end_date_validation'] = end_date_test\n",
    "\n",
    "    data_obj_hyperOpt = dataLoader(data_pars, features, n_steps_past=35,\n",
    "                                   n_steps_future=6,\n",
    "                                   allowed_gap=10,\n",
    "                                   scaler=StandardScaler())\n",
    "\n",
    "    experiment_id = searchBestHypers(num_samples=NUM_SAMPLES,\n",
    "                                     n_epochs_stop=N_EPOCHS_STOP,\n",
    "                                     max_num_epochs=MAX_NUM_EPOCHS,\n",
    "                                     grace_period=GRACE_PERIOD,\n",
    "                                     gpus_per_trial=0,\n",
    "                                     data_obj=data_obj_hyperOpt)\n",
    "    #experiment_id = main(num_samples=2, n_epochs_stop=3, max_num_epochs=2, gpus_per_trial=0, grace_period=1, data_obj=data_obj_hyperOpt)\n",
    "\n",
    "    # %%\n",
    "    print(\"\\n\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Now retrain model with optimal parameters\")\n",
    "    exeriment_path = code_path / \\\n",
    "        'hyper_experiments' / (experiment_id + '.json')\n",
    "\n",
    "    with open(exeriment_path) as json_file:\n",
    "        experiment = json.load(json_file)\n",
    "\n",
    "    best_model_dir = experiment['best_trial_dir']\n",
    "    par_file = Path(best_model_dir) / '..' / 'params.json'\n",
    "\n",
    "    with open(par_file) as json_file:\n",
    "        optHyps = json.load(open(par_file))\n",
    "\n",
    "    # Build model\n",
    "    with open(par_file) as json_file:\n",
    "        optHyps = json.load(open(par_file))\n",
    "\n",
    "    model = DilatedNet(h1=optHyps[\"h1\"],\n",
    "                       h2=optHyps[\"h2\"])\n",
    "\n",
    "    data_obj = dataLoader(data_pars, features, n_steps_past=35,\n",
    "                          n_steps_future=6,\n",
    "                          allowed_gap=10,\n",
    "                          scaler=StandardScaler())\n",
    "\n",
    "    train_cgm(optHyps, max_epochs=MAX_NUM_EPOCHS_FINAL,\n",
    "              grace_period=GRACE_PERIOD_FINAL,\n",
    "              n_epochs_stop=N_EPOCHS_STOP_FINAL,\n",
    "              data_obj=data_obj_hyperOpt,\n",
    "              useRayTune=False)\n",
    "    #train_cgm(optHyps, max_epochs= 3, grace_period=1, n_epochs_stop=2, data_obj=data_obj, useRayTune=False)\n",
    "\n",
    "    # Load best model state\n",
    "    model_state, optimizer_state = torch.load(code_path / 'src' / 'model_state_tmp' / 'checkpoint')\n",
    "    model.load_state_dict(model_state)\n",
    "\n",
    "    current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "    user = getpass.getuser()\n",
    "    model_id = f'id_{current_time}_{user}'\n",
    "    model_id = experiment_id\n",
    "\n",
    "    model_figure_path = figure_path / model_id\n",
    "    model_figure_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    best_model_path = model_path / model_id\n",
    "    best_model_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # Save best model\n",
    "    copyfile(code_path / 'src' / 'model_state_tmp' / 'checkpoint',\n",
    "             best_model_path / \"final_model_checkpoint\")\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # EVALUATE THE MODEL\n",
    "    # ---------------------------------------------------------------------\n",
    "    evaluationConfiguration = {\n",
    "        'distance': 1,\n",
    "        'hypo': 1,\n",
    "        'clarke': 1,\n",
    "        'parke': 1,\n",
    "        'lag': 1,\n",
    "        'plotLag': 1,\n",
    "        'plotTimeseries': 1\n",
    "    }\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    # Define evaluation class\n",
    "    evalObject = evaluateModel(data_obj_hyperOpt, model)\n",
    "\n",
    "    if evaluationConfiguration['distance']:\n",
    "        distance = evalObject.get_distanceAnalysis()\n",
    "    if evaluationConfiguration['hypo']:\n",
    "        hypo = evalObject.get_hypoAnalysis()\n",
    "    if evaluationConfiguration['lag']:\n",
    "        lag = evalObject.get_lagAnalysis(figure_path=model_figure_path)\n",
    "    if evaluationConfiguration['plotTimeseries']:\n",
    "        evalObject.get_timeSeriesPlot(figure_path=model_figure_path)\n",
    "    if evaluationConfiguration['clarke']:\n",
    "        clarkes, clarkes_prob = evalObject.clarkesErrorGrid('mg/dl', figure_path=model_figure_path)\n",
    "        #clarkes, clarkes_prob = evalObject.apply_clarkes_error_grid(\n",
    "            #'mg/dl', figure_path=model_figure_path)\n",
    "    if evaluationConfiguration['parke']:\n",
    "        parkes, parkes_prob = evalObject.apply_parkes_error_grid(\n",
    "            'mg/dl', figure_path=model_figure_path)\n",
    "        \n",
    "\n",
    "    scores.loc[str([train_data, val_data, test_data])] = [model_id,\n",
    "                                                          distance['rmse'], distance['mard'], distance['mae'],\n",
    "                                                          parkes_prob['A'], parkes_prob['B'], parkes_prob['C'], parkes_prob['D'], parkes_prob['E'],\n",
    "                                                          hypo['precision'], hypo['recall'], hypo['F1'], lag\n",
    "                                                          ]\n",
    "\n",
    "    # Save results\n",
    "    result_path.mkdir(exist_ok=True, parents=True)\n",
    "    scores.to_csv(result_path / 'all_scores.csv')\n",
    "    copyfile(par_file, model_figure_path / \"optPars.json\")\n",
    "    copyfile(code_path / 'hyper_experiments' / (experiment_id +\n",
    "                                                '.json'), model_figure_path / \"data_properties.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
